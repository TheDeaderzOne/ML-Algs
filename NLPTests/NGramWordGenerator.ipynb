{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e78e146",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ac9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up one directory from the notebook's location\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "project_root = os.path.join(notebook_dir, \"..\")\n",
    "\n",
    "# Add the project root to the system path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251eed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from NLPExperiments.NGramLanguageModel import NGramLanguage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161d443d",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6954f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENN = 4\n",
    "\n",
    "sentences = brown.sents()\n",
    "processed_sentences = [[\"<s>\"] * (ENN - 1) + [word.lower() for word in sentence] + [\"</s>\"] for sentence in sentences]\n",
    "\n",
    "words = [word.lower() for sentence in sentences for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a366095",
   "metadata": {},
   "source": [
    "Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1125d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGPT = NGramLanguage(ENN)\n",
    "\n",
    "ChatGPT.fit(processed_sentences, brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7e3cb",
   "metadata": {},
   "source": [
    "Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8977e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'hate', 'that']\n",
      "['somebody', 'once', 'told', 'me', 'the', 'time', 'has', 'come', 'for', 'the', 'american', 'people', 'as', 'president', 'of', 'the', 'export-import', 'bank', 'of', 'washington', 'in', 'india', 'incident', 'thereto', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I hate that\"\n",
    "sentence = sentence.split()\n",
    "\n",
    "print(sentence)\n",
    "current_sent = [\"somebody\", \"once\", \"told\", \"me\", \"the\"]\n",
    "\n",
    "print(ChatGPT.generate_sentence(current_sent, 50))\n",
    "# sentences should be lowercase\n",
    "\n",
    "# print(\"world\" in brown.words())\n",
    "# data preprocessing, add the N-1 \"Start\" Tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
